{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MahithaPoduvu/Mahitha_INFO5731_-Spring2023/blob/main/In_class_exercise_03_02282023_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nmi3tsgr5dtn"
      },
      "source": [
        "## The third In-class-exercise (2/28/2023, 40 points in total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtOYmocN5dts"
      },
      "source": [
        "The purpose of this exercise is to understand text representation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KX3UQHl75dtt"
      },
      "source": [
        "Question 1 (10 points): Describe an interesting text classification or text mining task and explain what kind of features might be useful for you to build the machine learning model. List your features and explain why these features might be helpful. You need to list at least five different types of features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgw6p3ha5dtu"
      },
      "outputs": [],
      "source": [
        "\n",
        "'''\n",
        "The text classification task chosen here is Sentiment analysis Tweets on Tesla car models. For this task, we want to build a machine learning model that can classify tweets as either positive or negative based on the sentiment expressed in the text.\n",
        "Some features that might be useful for this task include:\n",
        "\n",
        "1.Bag of words features: This represents the text as a set of words without any regard to the order of words in the text. Counting the frequency of each word in a tweet and using this as a feature for the model. This can capture important keywords that are associated with positive or negative sentiment.\n",
        "\n",
        "2.Part-of-speech features: Analyzing the syntactic structure of the text by identifying the part of speech of each word like noun, verb, adjective and using those tags as features. \n",
        "\n",
        "3.Sentiment lexicons: Using pre-built lists of words that are annotated with their sentiment polarity (positive, negative, or neutral) and counting the frequency of those words in the text. This can capture the use of words that are strongly associated with positive or negative sentiment.\n",
        "\n",
        "4.N-grams: Analyzing sequences of words of length n (e.g. bigrams, trigrams) and using those sequences as features. This can capture more complex patterns of language.\n",
        "\n",
        "5.Emotion features: To capture the emotional content in the text such as anger, fear, joy, sadness etc. These features can be useful for sentiment analysis as different emotions may indicate different sentiment.\n",
        "\n",
        "6.words embedding: Used to capture the context and meaning of the words in the text.\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install snscrape   # since it is installing every time i had made it to comment\n",
        "import snscrape.modules.twitter as sntwitter\n",
        "import snscrape.modules.twitter as twitterScrapper\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "tweet_data = [] #creating the emppty list\n",
        "number = 10   # for scrapping 10 tweets\n",
        "username = input() # to prompt user input , here I have scraped @officialavatar tweets\n",
        "d = f\" from:{username}\" # defining d as f from user name and to use it in loop\n",
        "\n",
        "for i, tweets in enumerate(sntwitter.TwitterSearchScraper(d).get_items()):\n",
        "  if i > number:\n",
        "    break\n",
        "  tweet_data.append({tweets.rawContent,tweets.user.username})\n",
        "  print(tweet_data)\n",
        "\n",
        "# to create the data frame\n",
        "df = pd.DataFrame(tweet_data,columns=['tweets','username'])\n",
        "print(df)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "df.to_csv(\"//content//drive//MyDrive//tweet_data.csv\")\n",
        "data = pd.read_csv(\"//content//drive//MyDrive//tweet_data.csv\")\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dw0hiMQrAOlS",
        "outputId": "05c6fc5d-66c2-47f1-c915-ff99fe92a099"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: snscrape in /usr/local/lib/python3.9/dist-packages (0.6.0.20230303)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/dist-packages (from snscrape) (4.6.3)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.9/dist-packages (from snscrape) (2.25.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from snscrape) (3.9.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.9/dist-packages (from snscrape) (4.9.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->snscrape) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->snscrape) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->snscrape) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->snscrape) (4.0.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->snscrape) (1.7.1)\n",
            "@officialavatar\n",
            "[{'officialavatar', 'Tune-in tonight to watch the #Oscars at 8ET/5PT on @ABCNetwork! #AvatarTheWayOfWater https://t.co/m8Z0doyYIA'}]\n",
            "[{'officialavatar', 'Tune-in tonight to watch the #Oscars at 8ET/5PT on @ABCNetwork! #AvatarTheWayOfWater https://t.co/m8Z0doyYIA'}, {'officialavatar', 'Return to Pandora whenever you want at home, only on Digital March 28. Get access to over three hours of never-before-seen extras when you add #AvatarTheWayOfWater to your movie collection. https://t.co/4dOhyjMU9l'}]\n",
            "[{'officialavatar', 'Tune-in tonight to watch the #Oscars at 8ET/5PT on @ABCNetwork! #AvatarTheWayOfWater https://t.co/m8Z0doyYIA'}, {'officialavatar', 'Return to Pandora whenever you want at home, only on Digital March 28. Get access to over three hours of never-before-seen extras when you add #AvatarTheWayOfWater to your movie collection. https://t.co/4dOhyjMU9l'}, {'Out now wherever books are sold.\\n\\nhttps://t.co/ozGgjDb3rd', 'officialavatar'}]\n",
            "[{'officialavatar', 'Tune-in tonight to watch the #Oscars at 8ET/5PT on @ABCNetwork! #AvatarTheWayOfWater https://t.co/m8Z0doyYIA'}, {'officialavatar', 'Return to Pandora whenever you want at home, only on Digital March 28. Get access to over three hours of never-before-seen extras when you add #AvatarTheWayOfWater to your movie collection. https://t.co/4dOhyjMU9l'}, {'Out now wherever books are sold.\\n\\nhttps://t.co/ozGgjDb3rd', 'officialavatar'}, {\"Get a closer look at the recoms of RDA's Project Phoenix and their gear in Avatar: The Way of Water — The Visual Dictionary from authors Dylan Cole, Zach Berger, Josh Izzo, Rey Perez, Ben Procter and @dkpublishing, featuring the art of @DylanColeArt  and @BProcterDesign. https://t.co/VK9frEEiuI\", 'officialavatar'}]\n",
            "[{'officialavatar', 'Tune-in tonight to watch the #Oscars at 8ET/5PT on @ABCNetwork! #AvatarTheWayOfWater https://t.co/m8Z0doyYIA'}, {'officialavatar', 'Return to Pandora whenever you want at home, only on Digital March 28. Get access to over three hours of never-before-seen extras when you add #AvatarTheWayOfWater to your movie collection. https://t.co/4dOhyjMU9l'}, {'Out now wherever books are sold.\\n\\nhttps://t.co/ozGgjDb3rd', 'officialavatar'}, {\"Get a closer look at the recoms of RDA's Project Phoenix and their gear in Avatar: The Way of Water — The Visual Dictionary from authors Dylan Cole, Zach Berger, Josh Izzo, Rey Perez, Ben Procter and @dkpublishing, featuring the art of @DylanColeArt  and @BProcterDesign. https://t.co/VK9frEEiuI\", 'officialavatar'}, {\"Like father, like son. Thanks to @chaaotika for this impressive drawing of Lo'ak. #NaviNationCreation https://t.co/Gc8qG0oXzb\", 'officialavatar'}]\n",
            "[{'officialavatar', 'Tune-in tonight to watch the #Oscars at 8ET/5PT on @ABCNetwork! #AvatarTheWayOfWater https://t.co/m8Z0doyYIA'}, {'officialavatar', 'Return to Pandora whenever you want at home, only on Digital March 28. Get access to over three hours of never-before-seen extras when you add #AvatarTheWayOfWater to your movie collection. https://t.co/4dOhyjMU9l'}, {'Out now wherever books are sold.\\n\\nhttps://t.co/ozGgjDb3rd', 'officialavatar'}, {\"Get a closer look at the recoms of RDA's Project Phoenix and their gear in Avatar: The Way of Water — The Visual Dictionary from authors Dylan Cole, Zach Berger, Josh Izzo, Rey Perez, Ben Procter and @dkpublishing, featuring the art of @DylanColeArt  and @BProcterDesign. https://t.co/VK9frEEiuI\", 'officialavatar'}, {\"Like father, like son. Thanks to @chaaotika for this impressive drawing of Lo'ak. #NaviNationCreation https://t.co/Gc8qG0oXzb\", 'officialavatar'}, {'Congratulations to #AvatarTheWayofWater for their Annie Award win for Best FX - Feature! #50thAnnieAwards https://t.co/pM1Ace2wXS', 'officialavatar'}]\n",
            "[{'officialavatar', 'Tune-in tonight to watch the #Oscars at 8ET/5PT on @ABCNetwork! #AvatarTheWayOfWater https://t.co/m8Z0doyYIA'}, {'officialavatar', 'Return to Pandora whenever you want at home, only on Digital March 28. Get access to over three hours of never-before-seen extras when you add #AvatarTheWayOfWater to your movie collection. https://t.co/4dOhyjMU9l'}, {'Out now wherever books are sold.\\n\\nhttps://t.co/ozGgjDb3rd', 'officialavatar'}, {\"Get a closer look at the recoms of RDA's Project Phoenix and their gear in Avatar: The Way of Water — The Visual Dictionary from authors Dylan Cole, Zach Berger, Josh Izzo, Rey Perez, Ben Procter and @dkpublishing, featuring the art of @DylanColeArt  and @BProcterDesign. https://t.co/VK9frEEiuI\", 'officialavatar'}, {\"Like father, like son. Thanks to @chaaotika for this impressive drawing of Lo'ak. #NaviNationCreation https://t.co/Gc8qG0oXzb\", 'officialavatar'}, {'Congratulations to #AvatarTheWayofWater for their Annie Award win for Best FX - Feature! #50thAnnieAwards https://t.co/pM1Ace2wXS', 'officialavatar'}, {'Congratulations to #AvatarTheWayofWater for their Annie Award win for Best Character Animation - Live Action! #50thAnnieAwards https://t.co/lEJBHxgAPk', 'officialavatar'}]\n",
            "[{'officialavatar', 'Tune-in tonight to watch the #Oscars at 8ET/5PT on @ABCNetwork! #AvatarTheWayOfWater https://t.co/m8Z0doyYIA'}, {'officialavatar', 'Return to Pandora whenever you want at home, only on Digital March 28. Get access to over three hours of never-before-seen extras when you add #AvatarTheWayOfWater to your movie collection. https://t.co/4dOhyjMU9l'}, {'Out now wherever books are sold.\\n\\nhttps://t.co/ozGgjDb3rd', 'officialavatar'}, {\"Get a closer look at the recoms of RDA's Project Phoenix and their gear in Avatar: The Way of Water — The Visual Dictionary from authors Dylan Cole, Zach Berger, Josh Izzo, Rey Perez, Ben Procter and @dkpublishing, featuring the art of @DylanColeArt  and @BProcterDesign. https://t.co/VK9frEEiuI\", 'officialavatar'}, {\"Like father, like son. Thanks to @chaaotika for this impressive drawing of Lo'ak. #NaviNationCreation https://t.co/Gc8qG0oXzb\", 'officialavatar'}, {'Congratulations to #AvatarTheWayofWater for their Annie Award win for Best FX - Feature! #50thAnnieAwards https://t.co/pM1Ace2wXS', 'officialavatar'}, {'Congratulations to #AvatarTheWayofWater for their Annie Award win for Best Character Animation - Live Action! #50thAnnieAwards https://t.co/lEJBHxgAPk', 'officialavatar'}, {'How do you create a whole world from scratch? @JimCameron recently sat down with #AvatarTheWayOfWater production designers, @BProcterDesign and @DylanColeArt to discuss the process of creating Pandora.\\n\\nhttps://t.co/y7YnbwuL8b', 'officialavatar'}]\n",
            "[{'officialavatar', 'Tune-in tonight to watch the #Oscars at 8ET/5PT on @ABCNetwork! #AvatarTheWayOfWater https://t.co/m8Z0doyYIA'}, {'officialavatar', 'Return to Pandora whenever you want at home, only on Digital March 28. Get access to over three hours of never-before-seen extras when you add #AvatarTheWayOfWater to your movie collection. https://t.co/4dOhyjMU9l'}, {'Out now wherever books are sold.\\n\\nhttps://t.co/ozGgjDb3rd', 'officialavatar'}, {\"Get a closer look at the recoms of RDA's Project Phoenix and their gear in Avatar: The Way of Water — The Visual Dictionary from authors Dylan Cole, Zach Berger, Josh Izzo, Rey Perez, Ben Procter and @dkpublishing, featuring the art of @DylanColeArt  and @BProcterDesign. https://t.co/VK9frEEiuI\", 'officialavatar'}, {\"Like father, like son. Thanks to @chaaotika for this impressive drawing of Lo'ak. #NaviNationCreation https://t.co/Gc8qG0oXzb\", 'officialavatar'}, {'Congratulations to #AvatarTheWayofWater for their Annie Award win for Best FX - Feature! #50thAnnieAwards https://t.co/pM1Ace2wXS', 'officialavatar'}, {'Congratulations to #AvatarTheWayofWater for their Annie Award win for Best Character Animation - Live Action! #50thAnnieAwards https://t.co/lEJBHxgAPk', 'officialavatar'}, {'How do you create a whole world from scratch? @JimCameron recently sat down with #AvatarTheWayOfWater production designers, @BProcterDesign and @DylanColeArt to discuss the process of creating Pandora.\\n\\nhttps://t.co/y7YnbwuL8b', 'officialavatar'}, {'Follow and Retweet for a chance to win the complete Avatar: The High Ground comic book series from author @Sherri_L_Smith and @DarkHorseComics! https://t.co/xYIen4Ws2W', 'officialavatar'}]\n",
            "[{'officialavatar', 'Tune-in tonight to watch the #Oscars at 8ET/5PT on @ABCNetwork! #AvatarTheWayOfWater https://t.co/m8Z0doyYIA'}, {'officialavatar', 'Return to Pandora whenever you want at home, only on Digital March 28. Get access to over three hours of never-before-seen extras when you add #AvatarTheWayOfWater to your movie collection. https://t.co/4dOhyjMU9l'}, {'Out now wherever books are sold.\\n\\nhttps://t.co/ozGgjDb3rd', 'officialavatar'}, {\"Get a closer look at the recoms of RDA's Project Phoenix and their gear in Avatar: The Way of Water — The Visual Dictionary from authors Dylan Cole, Zach Berger, Josh Izzo, Rey Perez, Ben Procter and @dkpublishing, featuring the art of @DylanColeArt  and @BProcterDesign. https://t.co/VK9frEEiuI\", 'officialavatar'}, {\"Like father, like son. Thanks to @chaaotika for this impressive drawing of Lo'ak. #NaviNationCreation https://t.co/Gc8qG0oXzb\", 'officialavatar'}, {'Congratulations to #AvatarTheWayofWater for their Annie Award win for Best FX - Feature! #50thAnnieAwards https://t.co/pM1Ace2wXS', 'officialavatar'}, {'Congratulations to #AvatarTheWayofWater for their Annie Award win for Best Character Animation - Live Action! #50thAnnieAwards https://t.co/lEJBHxgAPk', 'officialavatar'}, {'How do you create a whole world from scratch? @JimCameron recently sat down with #AvatarTheWayOfWater production designers, @BProcterDesign and @DylanColeArt to discuss the process of creating Pandora.\\n\\nhttps://t.co/y7YnbwuL8b', 'officialavatar'}, {'Follow and Retweet for a chance to win the complete Avatar: The High Ground comic book series from author @Sherri_L_Smith and @DarkHorseComics! https://t.co/xYIen4Ws2W', 'officialavatar'}, {\"Take a closer look at Pandora's unique sea life in The Art of Avatar: The Way of Water from author @TaraDBennett and @dkpublishing featuring the work of @BProcterDesign, @DylanColeArt, and Deborah Scott. Out now wherever books are sold. https://t.co/VU6FWMP1pf\", 'officialavatar'}]\n",
            "[{'officialavatar', 'Tune-in tonight to watch the #Oscars at 8ET/5PT on @ABCNetwork! #AvatarTheWayOfWater https://t.co/m8Z0doyYIA'}, {'officialavatar', 'Return to Pandora whenever you want at home, only on Digital March 28. Get access to over three hours of never-before-seen extras when you add #AvatarTheWayOfWater to your movie collection. https://t.co/4dOhyjMU9l'}, {'Out now wherever books are sold.\\n\\nhttps://t.co/ozGgjDb3rd', 'officialavatar'}, {\"Get a closer look at the recoms of RDA's Project Phoenix and their gear in Avatar: The Way of Water — The Visual Dictionary from authors Dylan Cole, Zach Berger, Josh Izzo, Rey Perez, Ben Procter and @dkpublishing, featuring the art of @DylanColeArt  and @BProcterDesign. https://t.co/VK9frEEiuI\", 'officialavatar'}, {\"Like father, like son. Thanks to @chaaotika for this impressive drawing of Lo'ak. #NaviNationCreation https://t.co/Gc8qG0oXzb\", 'officialavatar'}, {'Congratulations to #AvatarTheWayofWater for their Annie Award win for Best FX - Feature! #50thAnnieAwards https://t.co/pM1Ace2wXS', 'officialavatar'}, {'Congratulations to #AvatarTheWayofWater for their Annie Award win for Best Character Animation - Live Action! #50thAnnieAwards https://t.co/lEJBHxgAPk', 'officialavatar'}, {'How do you create a whole world from scratch? @JimCameron recently sat down with #AvatarTheWayOfWater production designers, @BProcterDesign and @DylanColeArt to discuss the process of creating Pandora.\\n\\nhttps://t.co/y7YnbwuL8b', 'officialavatar'}, {'Follow and Retweet for a chance to win the complete Avatar: The High Ground comic book series from author @Sherri_L_Smith and @DarkHorseComics! https://t.co/xYIen4Ws2W', 'officialavatar'}, {\"Take a closer look at Pandora's unique sea life in The Art of Avatar: The Way of Water from author @TaraDBennett and @dkpublishing featuring the work of @BProcterDesign, @DylanColeArt, and Deborah Scott. Out now wherever books are sold. https://t.co/VU6FWMP1pf\", 'officialavatar'}, {'Congratulations to Richard Baneham, Daniel Barrett, Joe Letteri and Eric Saindon for their BAFTA Awards win for Best Visual Effects for #AvatartheWayofWater! #EEBAFTAs https://t.co/02a67Ds6kf', 'officialavatar'}]\n",
            "                                               tweets  \\\n",
            "0                                      officialavatar   \n",
            "1                                      officialavatar   \n",
            "2   Out now wherever books are sold.\\n\\nhttps://t....   \n",
            "3   Get a closer look at the recoms of RDA's Proje...   \n",
            "4   Like father, like son. Thanks to @chaaotika fo...   \n",
            "5   Congratulations to #AvatarTheWayofWater for th...   \n",
            "6   Congratulations to #AvatarTheWayofWater for th...   \n",
            "7   How do you create a whole world from scratch? ...   \n",
            "8   Follow and Retweet for a chance to win the com...   \n",
            "9   Take a closer look at Pandora's unique sea lif...   \n",
            "10  Congratulations to Richard Baneham, Daniel Bar...   \n",
            "\n",
            "                                             username  \n",
            "0   Tune-in tonight to watch the #Oscars at 8ET/5P...  \n",
            "1   Return to Pandora whenever you want at home, o...  \n",
            "2                                      officialavatar  \n",
            "3                                      officialavatar  \n",
            "4                                      officialavatar  \n",
            "5                                      officialavatar  \n",
            "6                                      officialavatar  \n",
            "7                                      officialavatar  \n",
            "8                                      officialavatar  \n",
            "9                                      officialavatar  \n",
            "10                                     officialavatar  \n",
            "Mounted at /content/drive\n",
            "    Unnamed: 0                                             tweets  \\\n",
            "0            0                                     officialavatar   \n",
            "1            1                                     officialavatar   \n",
            "2            2  Out now wherever books are sold.\\n\\nhttps://t....   \n",
            "3            3  Get a closer look at the recoms of RDA's Proje...   \n",
            "4            4  Like father, like son. Thanks to @chaaotika fo...   \n",
            "5            5  Congratulations to #AvatarTheWayofWater for th...   \n",
            "6            6  Congratulations to #AvatarTheWayofWater for th...   \n",
            "7            7  How do you create a whole world from scratch? ...   \n",
            "8            8  Follow and Retweet for a chance to win the com...   \n",
            "9            9  Take a closer look at Pandora's unique sea lif...   \n",
            "10          10  Congratulations to Richard Baneham, Daniel Bar...   \n",
            "\n",
            "                                             username  \n",
            "0   Tune-in tonight to watch the #Oscars at 8ET/5P...  \n",
            "1   Return to Pandora whenever you want at home, o...  \n",
            "2                                      officialavatar  \n",
            "3                                      officialavatar  \n",
            "4                                      officialavatar  \n",
            "5                                      officialavatar  \n",
            "6                                      officialavatar  \n",
            "7                                      officialavatar  \n",
            "8                                      officialavatar  \n",
            "9                                      officialavatar  \n",
            "10                                     officialavatar  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orlq26EU5dtx"
      },
      "source": [
        "Question 2 (10 points): Write python code to extract these features you discussed above. You can collect a few sample text data for the feature extraction. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-gPhbW95dty"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"//content//drive//MyDrive//tweet_data.csv\")\n",
        "print(data.head)\n",
        "data.info # to get the info of the data\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing libaries\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "import nltk\n",
        "%matplotlib inline\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# for preprocessing data\n",
        "# removes pattern in the input text\n",
        "def remove_pattern(input_txt, pattern):\n",
        "    r = re.findall(pattern, input_txt)\n",
        "    for word in r:\n",
        "        input_txt = re.sub(word, \"\", input_txt)\n",
        "    return input_txt\n",
        "#data.head()\n",
        "#Lowercase all texts\n",
        "data['tweets'] = data['tweets'].str.lower()\n",
        "data.head\n",
        "# remove twitter handles (@user)\n",
        "data['clean_tweets'] = np.vectorize(remove_pattern)(data['tweets'], \"@[\\w]*\")\n",
        "#data.head\n",
        "# remove special characters, numbers and punctuations\n",
        "data['clean_tweets'] = data['clean_tweets'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
        "#data.head()\n",
        "# remove short words less tha 3 characters long\n",
        "data['clean_tweets'] = data['clean_tweets'].apply(lambda x: \" \".join([w for w in x.split() if len(w)>3]))\n",
        "#data.head()\n"
      ],
      "metadata": {
        "id": "uHu5P1ow_B-C"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sentiment lexicon\n",
        "#!pip install TextBlob\n",
        "from textblob import TextBlob\n",
        "\n",
        "def getTextSubjectivity(tokenized_tweet):\n",
        "  return TextBlob(tokenized_tweet).sentiment.subjectivity\n",
        "#to get text polarity\n",
        "def getTextPolarity(tokenized_tweet):\n",
        "  return TextBlob(tokenized_tweet).sentiment.polarity\n",
        "\n",
        "data_subjectivity = data['clean_tweets'].apply(getTextSubjectivity)\n",
        "data_polarity = data['clean_tweets'].apply(getTextSubjectivity)\n",
        "#print(data_subjectvity,data_polarity)\n",
        "\n",
        "def getTextAnalysis(a):\n",
        "  if a<0:\n",
        "    return \"Negative\"\n",
        "  elif a==0:\n",
        "    return \"Neutral\"\n",
        "  else:\n",
        "    return \"Positive\"\n",
        "data_score= data_polarity.apply(getTextAnalysis)\n",
        "\n",
        "# to create the data frame\n",
        "frame = { 'Tweets': data['tweets'], 'Polarity': data_polarity, 'Score' : data_score, 'Subjectivity' : data_subjectivity }\n",
        "#Creating DataFrame by passing Dictionary\n",
        "df = pd.DataFrame(frame)\n",
        "#print(df.head)\n",
        "\n",
        "#to get the percentage of positive tweets\n",
        "positive = df[df['Score']==\"Positive\"]\n",
        "print(str(positive.shape[0]/(df.shape[0])*100)+\"% of positive tweets\")\n",
        "pos =positive.shape[0]/df.shape[0]*100\n",
        "\n",
        "#to get the percentage of negative tweets\n",
        "negative = df[df['Score']==\"Negative\"]\n",
        "print(str(negative.shape[0]/(df.shape[0])*100)+\"% of negative tweets\")\n",
        "pos = negative.shape[0]/df.shape[0]*100\n",
        "\n",
        "#to get the percentage of neutral tweets\n",
        "neutral = df[df['Score']==\"Neutral\"]\n",
        "print(str(neutral.shape[0]/(df.shape[0])*100)+\"% of neutral tweets\")\n",
        "pos = neutral.shape[0]/df.shape[0]*100\n",
        "\n",
        "# plot bar graph \n",
        "labels=df.groupby('Score').count().index.values\n",
        "values = df.groupby('Score').size().values\n",
        "#plt.bar(labels,values)\n"
      ],
      "metadata": {
        "id": "83Apj2Ymi7hx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#bag of words\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(data['clean_tweets'])\n",
        "vectorizer.get_feature_names_out()\n",
        "vectorizer.vocabulary_"
      ],
      "metadata": {
        "id": "OU3dEf6swijg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#N-grams\n",
        "TextBlob(data['clean_tweets'][0]).ngrams(2)"
      ],
      "metadata": {
        "id": "kuN-UB6Vw-uM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#parts of speech tagging\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk import pos_tag, word_tokenize, RegexpParser\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "for i in df.index:\n",
        "  doc = nlp(df.at[i,'Tweets'])\n",
        "  count = doc.count_by(spacy.attrs.POS)\n",
        "  for k,j in count.items():\n",
        "    print(doc.vocab[k].text, \"|\",j)\n",
        "\n",
        "  tagged = pos_tag(word_tokenize(df.at[0,'Tweets']))\n",
        "\n",
        "  #Extract all parts of speech from any text\n",
        "  chunker = RegexpParser(\"\"\"\n",
        "                    NP: {<DT>?<JJ>*<NN>} #To extract Noun Phrases\n",
        "                    P: {<IN>}            #To extract Prepositions\n",
        "                    V: {<V.*>}           #To extract Verbs\n",
        "                    PP: {<p> <NP>}       #To extract Prepositional Phrases\n",
        "                    VP: {<V> <NP|PP>*}   #To extract Verb Phrases\n",
        "                    \"\"\")\n",
        "\n",
        "  # Print all parts of speech in above sentence\n",
        "  output = chunker.parse(tagged)\n",
        "  print(output)\n",
        "  displacy.render(doc, style='dep', jupyter=True, options={'distance': 100})"
      ],
      "metadata": {
        "id": "l7-JPDtSsQrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#words embedding\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "from gensim.models import KeyedVectors # load the Stanford GloVe model\n",
        "glove_input_file = '/content/gdrive/My Drive/glove.6B.100d.txt'\n",
        "word2vec_output_file = '/content/gdrive/My Drive/glove.6B.100d.txt.word2vec'\n",
        "glove_model = glove2word2vec(glove_input_file, word2vec_output_file)\n",
        "\n",
        "\n",
        "filename = '/content/gdrive/My Drive/glove.6B.100d.txt.word2vec'\n",
        "model = KeyedVectors.load_word2vec_format(filename, binary=False)\n",
        "model['go']\n",
        "model['away']\n",
        "(model['go'] + model['away'])/2"
      ],
      "metadata": {
        "id": "M4KbO8DGuBL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHJaFY7M5dtz"
      },
      "source": [
        "Question 3 (10 points): Use any of the feature selection methods mentioned in this paper \"Deng, X., Li, Y., Weng, J., & Zhang, J. (2019). Feature selection for text classification: A review. Multimedia Tools & Applications, 78(3).\" Select the most important features you extracted above, rank the features based on their importance in the descending order. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0oWBk1lL5dt0"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "The most important feature extracted in above data is sentiment lexicon as it gives the true emotion of tweets(positive, negative,netural)\n",
        "ranking the features in descending order: \n",
        "1.sentiment Lexicon\n",
        "2.words embedding\n",
        "3.parts of speech tagging\n",
        "4.N-grams\n",
        "5.bag of words\n",
        "# Since I didnot get access to the article mentioned above I made above statements by considering the materials on websites.\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AOliJ2C5dt1"
      },
      "source": [
        "Question 4 (10 points): Write python code to rank the text based on text similarity. Based on the text data you used for question 2, design a query to match the most relevant docments. Please use the BERT model to represent both your query and the text data, then calculate the cosine similarity between the query and each text in your data. Rank the similary with descending order. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQ5yWloc5dt6",
        "outputId": "e52b679b-c1bf-49c4-9565-5de54770a275"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "#Finding the similarity between tweets\n",
        "#!pip install sentence-transformers\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "sentences = df['Tweets']\n",
        "\n",
        "model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
        "sentence_embeddings = model.encode(sentences)\n",
        "sentence_embeddings.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "cosine_similarity(\n",
        "    [sentence_embeddings[0]],\n",
        "    sentence_embeddings[1:]\n",
        ")"
      ],
      "metadata": {
        "id": "gxb1KMaahF5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel # to initialise model and tokenizer\n",
        "import torch\n",
        "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/bert-base-nli-mean-tokens')\n",
        "model = AutoModel.from_pretrained('sentence-transformers/bert-base-nli-mean-tokens')\n",
        "sentences = df['Tweets']\n",
        "\n",
        "tokens = {'input_ids': [], 'attention_mask': []}\n",
        "for sentence in sentences:\n",
        "    # encode each sentence and append to dictionary\n",
        "    new_tokens = tokenizer.encode_plus(sentence, max_length=128,\n",
        "                                       truncation=True, padding='max_length',\n",
        "                                       return_tensors='pt')\n",
        "    tokens['input_ids'].append(new_tokens['input_ids'][0])\n",
        "    tokens['attention_mask'].append(new_tokens['attention_mask'][0])\n",
        "\n",
        "# reformat list of tensors into single tensor\n",
        "tokens['input_ids'] = torch.stack(tokens['input_ids'])\n",
        "tokens['attention_mask'] = torch.stack(tokens['attention_mask'])\n",
        "outputs = model(**tokens)\n",
        "outputs.keys()\n",
        "\n",
        "embeddings = outputs.last_hidden_state\n",
        "embeddings\n",
        "embeddings.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aGwih7CpG98",
        "outputId": "ac6aa7d8-bd39-4363-f527-02ba4e47d10e"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([11, 128, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_mask = tokens['attention_mask']\n",
        "attention_mask.shape\n",
        "mask = attention_mask.unsqueeze(-1).expand(embeddings.size()).float()\n",
        "mask.shape\n",
        "mask\n"
      ],
      "metadata": {
        "id": "vxaojq6rt8KE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "masked_embeddings = embeddings * mask\n",
        "masked_embeddings.shape\n",
        "masked_embeddings"
      ],
      "metadata": {
        "id": "BB-QVgwDuPr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summed = torch.sum(masked_embeddings, 1)\n",
        "summed.shape\n",
        "summed_mask = torch.clamp(mask.sum(1), min=1e-9)\n",
        "summed_mask.shape\n",
        "summed_mask\n",
        "mean_pooled = summed / summed_mask\n",
        "mean_pooled"
      ],
      "metadata": {
        "id": "j1vN4w00upqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#as we get dense vector, cosine simialrity between tweets \n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "mean_pooled = mean_pooled.detach().numpy()\n",
        "\n",
        "# calculate\n",
        "cosine_similarity(\n",
        "    [mean_pooled[0]],\n",
        "    mean_pooled[1:]\n",
        ")"
      ],
      "metadata": {
        "id": "-zjzSJUHvT4O"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}